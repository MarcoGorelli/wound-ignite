{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import ALL\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "#  Code for computing the RPS and IR scores for a given evaluation period\n",
    "###########################################################################\n",
    "\n",
    "#For simplicity, in this example it is assumed that the data provided cover a single evaluation period.\n",
    "#This period is specified through the min/max date of the asset prices data set.\n",
    "#If you wish to compute RPS/IR for multiple periods, you'll have to execute \n",
    "#the script multiple times, each time using a different, appropriate input.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import stdev\n",
    "\n",
    "\n",
    "#Read asset prices data (as provided by the M6 submission platform)\n",
    "\n",
    "#Read submission file (similar to the template provided by the M6 submission platform)\n",
    "\n",
    "\n",
    "#Function for computing RPS\n",
    "def RPS_calculation(hist_data, submission, asset_no=100):\n",
    "    \n",
    "    if hist_data.shape[0]<=asset_no:\n",
    "        return np.nan    \n",
    "    \n",
    "    asset_id = pd.unique(hist_data.symbol)\n",
    "    \n",
    "    for i in range(len(pd.unique(hist_data.date))):\n",
    "        if len(hist_data[hist_data.date == pd.unique(hist_data.date)[i]])<len(asset_id):\n",
    "            for asset in [x for x in asset_id if x not in hist_data[hist_data.date == pd.unique(hist_data.date)[i]].symbol.values]:\n",
    "                right_price = hist_data[hist_data.symbol==asset].sort_values(by='date')\n",
    "                right_price = right_price[right_price.date <= pd.unique(hist_data.date)[i]]\n",
    "                right_price = right_price.price.iloc[-1]\n",
    "                hist_data = hist_data.append({'date' : pd.unique(hist_data.date)[i],\n",
    "                                               'symbol' : asset,\n",
    "                                               'price' : right_price}, ignore_index=True)\n",
    "\n",
    "    #Compute percentage returns\n",
    "    asset_id = sorted(asset_id) \n",
    "\n",
    "    #Compute percentage returns\n",
    "    returns = pd.DataFrame(columns = [\"ID\", \"Return\"])\n",
    "    \n",
    "    min_date = min(hist_data.date)\n",
    "    max_date = max(hist_data.date)\n",
    "    \n",
    "    for i in range(0,len(asset_id)):\n",
    "        temp = hist_data.loc[hist_data.symbol==asset_id[i]]\n",
    "        \n",
    "        open_price = float(temp.loc[temp.date==min_date].price)\n",
    "        close_price = float(temp.loc[temp.date==max_date].price)\n",
    "        \n",
    "        returns = returns.append({'ID': temp.symbol.iloc[0], \n",
    "                                'Return': (close_price - open_price)/open_price}, ignore_index=True)\n",
    "\n",
    "    #Define the relevant position of each asset\n",
    "    ranking = pd.DataFrame(columns=[\"ID\", \"Position\", \"Return\"])\n",
    "    ranking.ID = list(asset_id)\n",
    "    ranking.Return = returns.Return\n",
    "    ranking.Position = ranking.Return.rank(method = 'min')\n",
    "\n",
    "    #Handle Ties\n",
    "    Series_per_position = pd.DataFrame(columns=[\"Position\",\"Series\", \"Rank\", \"Rank1\", \"Rank2\",\"Rank3\", \"Rank4\", \"Rank5\"])\n",
    "    Series_per_position.Position = list(pd.unique(ranking.Position.sort_values(ascending=True)))\n",
    "    temp = ranking.Position.value_counts()\n",
    "    temp = pd.DataFrame(zip(temp.index, temp), columns = [\"Rank\", \"Occurencies\"])\n",
    "    temp = temp.sort_values(by = [\"Rank\"],ascending=True)\n",
    "    Series_per_position.Series = list(temp.Occurencies)\n",
    "    Series_per_position\n",
    "\n",
    "    total_ranks = Series_per_position.Position.values[-1]\n",
    "    for i in range(0,Series_per_position.shape[0]):\n",
    "    \n",
    "        start_p = Series_per_position.Position[i]\n",
    "        end_p = Series_per_position.Position[i] + Series_per_position.Series[i]\n",
    "        temp = pd.DataFrame(columns = [\"Position\",\"Rank\", \"Rank1\", \"Rank2\", \"Rank3\", \"Rank4\",\"Rank5\"])\n",
    "        temp.Position = list(range(int(start_p),int(end_p)))\n",
    "\n",
    "        if(temp.loc[temp.Position.isin(list(range(1,int(0.2*total_ranks+1))))].empty==False):\n",
    "            temp.loc[temp.Position.isin(list(range(1,int(0.2*total_ranks+1))))] = temp.loc[temp.Position.isin(list(range(1,int(0.2*total_ranks+1))))].assign(Rank=1)\n",
    "            temp.loc[temp.Position.isin(list(range(1,int(0.2*total_ranks+1))))] = temp.loc[temp.Position.isin(list(range(1,int(0.2*total_ranks+1))))].assign(Rank1=1.0)\n",
    "\n",
    "        elif(temp.loc[temp.Position.isin(list(range(int(0.2*total_ranks+1),int(0.4*total_ranks+1))))].empty==False):\n",
    "            temp.loc[temp.Position.isin(list(range(int(0.2*total_ranks+1),int(0.4*total_ranks+1))))] = temp.loc[temp.Position.isin(list(range(int(0.2*total_ranks+1),int(0.4*total_ranks+1))))].assign(Rank=2)\n",
    "            temp.loc[temp.Position.isin(list(range(int(0.2*total_ranks+1),int(0.4*total_ranks+1))))] = temp.loc[temp.Position.isin(list(range(int(0.2*total_ranks+1),int(0.4*total_ranks+1))))].assign(Rank2=1.0)\n",
    "\n",
    "        elif(temp.loc[temp.Position.isin(list(range(int(0.4*total_ranks+1),int(0.6*total_ranks+1))))].empty==False):\n",
    "            temp.loc[temp.Position.isin(list(range(int(0.4*total_ranks+1),int(0.6*total_ranks+1))))] = temp.loc[temp.Position.isin(list(range(int(0.4*total_ranks+1),int(0.6*total_ranks+1))))].assign(Rank=3)\n",
    "            temp.loc[temp.Position.isin(list(range(int(0.4*total_ranks+1),int(0.6*total_ranks+1))))] = temp.loc[temp.Position.isin(list(range(int(0.4*total_ranks+1),int(0.6*total_ranks+1))))].assign(Rank3=1.0)\n",
    "\n",
    "        elif(temp.loc[temp.Position.isin(list(range(int(0.6*total_ranks+1),int(0.8*total_ranks+1))))].empty==False):\n",
    "            temp.loc[temp.Position.isin(list(range(int(0.6*total_ranks+1),int(0.8*total_ranks+1))))] = temp.loc[temp.Position.isin(list(range(int(0.6*total_ranks+1),int(0.8*total_ranks+1))))].assign(Rank=4)\n",
    "            temp.loc[temp.Position.isin(list(range(int(0.6*total_ranks+1),int(0.8*total_ranks+1))))] = temp.loc[temp.Position.isin(list(range(int(0.6*total_ranks+1),int(0.8*total_ranks+1))))].assign(Rank4=1.0)\n",
    "\n",
    "        elif(temp.loc[temp.Position.isin(list(range(int(0.8*total_ranks+1),int(total_ranks+1))))].empty==False):\n",
    "            temp.loc[temp.Position.isin(list(range(int(0.8*total_ranks+1),int(total_ranks+1))))] = temp.loc[temp.Position.isin(list(range(int(0.8*total_ranks+1),int(total_ranks+1))))].assign(Rank=5)\n",
    "            temp.loc[temp.Position.isin(list(range(int(0.8*total_ranks+1),int(total_ranks+1))))] = temp.loc[temp.Position.isin(list(range(int(0.8*total_ranks+1),int(total_ranks+1))))].assign(Rank5=1.0)\n",
    "        temp = temp.fillna(0)\n",
    "        Series_per_position.iloc[i,2:Series_per_position.shape[1]] = temp.mean(axis = 0).iloc[1:temp.shape[1]]\n",
    "\n",
    "    Series_per_position = Series_per_position.drop('Series', axis = 1)\n",
    "    ranking = pd.merge(ranking,Series_per_position, on = \"Position\")\n",
    "    ranking = ranking[[\"ID\", \"Return\", \"Position\", \"Rank\", \"Rank1\", \"Rank2\", \"Rank3\", \"Rank4\", \"Rank5\"]]\n",
    "    ranking = ranking.sort_values([\"Position\"])\n",
    "    \n",
    "    #Evaluate submission\n",
    "    rps_sub = []\n",
    "    #for aid in list((pd.unique(ranking.ID))):\n",
    "    for aid in asset_id:\n",
    "\n",
    "        target = np.cumsum(ranking.loc[ranking.ID==aid].iloc[:,4:9].values).tolist()\n",
    "        frc = np.cumsum(submission.loc[submission.ID==aid].iloc[:,1:6].values).tolist()\n",
    "        rps_sub.append(np.mean([(a - b)**2 for a, b in zip(target, frc)]))\n",
    "    submission[\"RPS\"] = rps_sub\n",
    "    \n",
    "    output = {'RPS' : np.mean(rps_sub),\n",
    "              'details' : submission}\n",
    "    \n",
    "    return(output)\n",
    "   \n",
    "#Function for computing IR\n",
    "def IR_calculation(hist_data, submission):\n",
    "    \n",
    "    asset_id = pd.unique(hist_data.symbol)\n",
    "    \n",
    "    for i in range(len(pd.unique(hist_data.date))):\n",
    "        if len(hist_data[hist_data.date == pd.unique(hist_data.date)[i]])<len(asset_id):\n",
    "            for asset in [x for x in asset_id if x not in hist_data[hist_data.date == pd.unique(hist_data.date)[i]].symbol.values]:\n",
    "                right_price = hist_data[hist_data.symbol==asset].sort_values(by='date')\n",
    "                right_price = right_price[right_price.date <= pd.unique(hist_data.date)[i]]\n",
    "                right_price = right_price.price.iloc[-1]\n",
    "                hist_data = hist_data.append({'date' : pd.unique(hist_data.date)[i],\n",
    "                                               'symbol' : asset,\n",
    "                                               'price' : right_price}, ignore_index=True)\n",
    "\n",
    "\n",
    "    asset_id = sorted(asset_id) \n",
    "\n",
    "    #Compute percentage returns\n",
    "    returns = pd.DataFrame(columns = [\"ID\", \"Return\"])\n",
    "\n",
    "    #Investment weights\n",
    "    weights = submission[[\"ID\",\"Decision\"]]\n",
    "\n",
    "    RET = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(asset_id)):\n",
    "        temp = hist_data.loc[hist_data.symbol==asset_id[i]]\n",
    "        temp = temp.sort_values(by='date')\n",
    "        temp.reset_index(inplace=True, drop=True)\n",
    "        RET = RET.append(temp.price.pct_change()*weights.loc[weights.ID==asset_id[i]].Decision.values[0])\n",
    "\n",
    "    ret = np.log(1+RET.sum()[1:])\n",
    "    sum_ret = sum(ret)\n",
    "    sdp = stdev(ret)\n",
    "    \n",
    "    output = {'IR' : sum_ret/sdp,\n",
    "              'details' : list(ret)}\n",
    "    \n",
    "    \n",
    "    return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "raw_asset_data = pd.read_csv('/kaggle/input/cache-yfinance-data/data_Adj Close.csv')\n",
    "all_asset_data = (\n",
    "    raw_asset_data\n",
    "    .melt(id_vars='Date', var_name='symbol', value_name='price')\n",
    "    .rename(columns={'Date': 'date'})\n",
    "    .reindex(columns=['symbol', 'date', 'price'])\n",
    ")\n",
    "all_asset_data['date'] = pd.to_datetime(all_asset_data['date'])\n",
    "all_asset_data = all_asset_data[all_asset_data['price'].notna()].copy()\n",
    "# dfs = {}\n",
    "# for grp, df in all_asset_data.groupby('symbol'):\n",
    "#     dfs[grp] = df.set_index('date').resample('D').mean().fillna(method='ffill')\n",
    "# all_asset_data = pd.concat(dfs).reset_index().rename(columns={'level_0': 'symbol'})\n",
    "\n",
    "import collections\n",
    "results = collections.defaultdict(lambda:collections.defaultdict(list))\n",
    "file = '/kaggle/input/precise-submit/submission.csv'\n",
    "start = pd.date_range(end=pd.Timestamp.now().date(), periods=4, freq='4W-Fri')[-2]\n",
    "end = pd.date_range(end=pd.Timestamp.now().date(), periods=4, freq='4W-Fri')[-1]\n",
    "print(start, end)\n",
    "asset_data = all_asset_data[all_asset_data['date'].between(start, end)]\n",
    "hist_data = asset_data\n",
    "\n",
    "submission_data = pd.read_csv(file)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    rps = RPS_calculation(hist_data = asset_data , submission = submission_data)['RPS']\n",
    "    ir = IR_calculation(hist_data, submission_data)['IR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd3b2f3f70e53b51b6a11b95690f705f4b206915c791b840b94c0056c908d8d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
