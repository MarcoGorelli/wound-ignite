{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/microprediction/precise/blob/main/examples_colab_notebooks/elo_ratings_and_code_urls_2022_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIHJnIVINZ7b"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/microprediction/precise.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cd0J8WX-RelH"
   },
   "source": [
    "### Report current Elo ratings\n",
    "Be a little patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qy-f0jV3NkGn"
   },
   "outputs": [],
   "source": [
    "from precise.skatervaluation.battleutil.compilingeloratings import elo_from_win_files\n",
    "from pprint import pprint \n",
    "elos = elo_from_win_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61YqUwxpUnMy",
    "outputId": "7f329c39-94e9-4ec4-ecf0-b9815ed07b56"
   },
   "outputs": [],
   "source": [
    "the_categories = [c for c,_ in elos]\n",
    "print(the_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMz5kyDwSR_f",
    "outputId": "c1376425-37eb-49f2-cb71-8d95e1a9b426"
   },
   "outputs": [],
   "source": [
    "pprint(elos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOL4sI47R1vD"
   },
   "source": [
    "## Print Elos and code locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASbpDgVpR4_6",
    "outputId": "e468521f-6289-4fe5-e03a-42d656d6e32a"
   },
   "outputs": [],
   "source": [
    "from precise.whereami import url_from_skater_name\n",
    "n_top = 15 # <-- Number to print per category\n",
    "results_with_urls = dict()\n",
    "for cat, cat_elos in elos:\n",
    "    elos_w_code = sorted( [ (rating,name, url_from_skater_name(name)) for name,rating in cat_elos.items()],reverse=True)[:n_top]\n",
    "    results_with_urls[cat] = elos_w_code\n",
    "pprint(results_with_urls)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOn7972shpERxb+yssB4/aB",
   "include_colab_link": true,
   "name": "elo_ratings_and_code_urls_2022_02.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
